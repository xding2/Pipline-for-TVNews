{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "058c3a1c-4659-40e5-9535-eebd62e548ee",
   "metadata": {},
   "source": [
    "## PIPLINE.3 - Topic Model\n",
    "Here is the pipline for applying `ETM` on the real content. There are two public repo for `ETM` model and both of pulic repos are from this paper: [topic model](https://arxiv.org/abs/1907.04907). Please read this paper at the beginning.\n",
    "\n",
    "Here are two public repo, I suggest using the **first** one, which is already a **encapsulation**, so there is no need to reproduce the source code from original paper:\n",
    "+ https://github.com/lffloyd/embedded-topic-model\n",
    "+ https://github.com/adjidieng/ETM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a58e586a-08e5-4003-8d58-41fde3dca20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install embedded_topic_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10ab7fe-c69b-41aa-bba5-d7206b26633b",
   "metadata": {},
   "source": [
    "### Read the dataset from your location\n",
    "\n",
    "read the 'content' colunm\n",
    "\n",
    "i.e df['content col name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "270fccc2-566a-437b-b1b5-bf88ff5d7454",
   "metadata": {},
   "outputs": [],
   "source": [
    "paremeter = []\n",
    "with open('parameter.txt') as f:\n",
    "    contents = f.read()\n",
    "    paremeter = contents.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ccec24-1e7a-473a-97e2-9d85b69b4af9",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "1. lower\n",
    "2. remove punctuation\n",
    "3. **remove stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d4632c1-689a-4e6a-bde9-67a7c68ec416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedded_topic_model.utils import embedding, preprocessing\n",
    "import os\n",
    "import pandas as pd\n",
    "from embedded_topic_model.utils import embedding\n",
    "\n",
    "# read and preprocess\n",
    "df = pd.read_csv('/home/xiaohan/tvnews/csvdata/2009/CNN_20090826_040000_Larry_King_Live.csv')\n",
    "df['sentence'] = df['sentence'].str.lower()\n",
    "df['sentence'] = df['sentence'].str.replace(r'[^\\w\\s]+', '')\n",
    "df['sentence'] = df['sentence'].str.replace('{','')\n",
    "df['sentence'] = df['sentence'].str.replace('}','')\n",
    "\n",
    "#df['sentence']: do remove stopwords from nltk or other local stopwords\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# read the col to a list\n",
    "sentences = df['sentence'].values.tolist()\n",
    "\n",
    "#sentences\n",
    "vocabulary, train_dataset, _, = preprocessing.create_etm_datasets(\n",
    "    sentences, \n",
    "    min_df=float(paremeter[0]), \n",
    "    max_df=float(paremeter[1]), \n",
    "    train_size=float(paremeter[2]),  \n",
    ")\n",
    "\n",
    "# Training word2vec embeddings\n",
    "embeddings_mapping = embedding.create_word2vec_embedding_from_dataset(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "002a520c-ce57-4a55-80a2-fac85db1e527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<embedded_topic_model.models.etm.ETM at 0x7ff6d016a6a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from embedded_topic_model.models.etm import ETM\n",
    "\n",
    "# Training an ETM instance\n",
    "etm_instance = ETM(\n",
    "    vocabulary,\n",
    "    embeddings=embeddings_mapping,  # You can pass here the path to a word2vec file or\n",
    "                                    # a KeyedVectors instance\n",
    "    num_topics=int(paremeter[3]),\n",
    "    epochs=int(paremeter[4]),\n",
    "    debug_mode=False,\n",
    "    train_embeddings=False\n",
    ")\n",
    "etm_instance.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e65f7da7-126d-4016-bca9-3571ead78062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topics word will be:\n",
      "[['the', 'to', 'and', 'you', 'of']]\n"
     ]
    }
   ],
   "source": [
    "topics = etm_instance.get_topics(int(paremeter[5]))\n",
    "print('topics word will be:')\n",
    "print(topics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
